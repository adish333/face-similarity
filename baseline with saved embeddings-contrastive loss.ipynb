{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from itertools import combinations\n",
    "import random\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "import pickle\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image1</th>\n",
       "      <th>image2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/Billy_Crystal_0001.jpg</td>\n",
       "      <td>data/Billy_Crystal_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/Britney_Spears_0008.jpg</td>\n",
       "      <td>data/Britney_Spears_0014.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/Joseph_Deiss_0002.jpg</td>\n",
       "      <td>data/Joseph_Deiss_0003.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/Barbra_Streisand_0001.jpg</td>\n",
       "      <td>data/Barbra_Streisand_0002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/Rebekah_Chantay_Revels_0001.jpg</td>\n",
       "      <td>data/Rebekah_Chantay_Revels_0002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image1                                image2  \\\n",
       "0           data/Billy_Crystal_0001.jpg           data/Billy_Crystal_0003.jpg   \n",
       "1          data/Britney_Spears_0008.jpg          data/Britney_Spears_0014.jpg   \n",
       "2            data/Joseph_Deiss_0002.jpg            data/Joseph_Deiss_0003.jpg   \n",
       "3        data/Barbra_Streisand_0001.jpg        data/Barbra_Streisand_0002.jpg   \n",
       "4  data/Rebekah_Chantay_Revels_0001.jpg  data/Rebekah_Chantay_Revels_0002.jpg   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"face_embeddings.pkl\", 'rb') as file:\n",
    "    embd_dict = pickle.load(file)\n",
    "    \n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, df, embd_dict, embd_size, batch_size=8, shuffle=True):\n",
    "        'Initialization'\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.df = df\n",
    "        self.list_IDs = list_IDs\n",
    "        self.embd_dict = embd_dict\n",
    "        self.embd_size = embd_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_batch):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X1 = np.empty((self.batch_size, self.embd_size))\n",
    "        X2 = np.empty((self.batch_size, self.embd_size))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_batch):\n",
    "            # Store sample\n",
    "            img1 = self.df['image1'].iloc[ID]\n",
    "            img2 = self.df['image2'].iloc[ID]\n",
    "            X1[i,] = self.embd_dict[img1]\n",
    "            X2[i,] = self.embd_dict[img2]\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.df['label'].iloc[ID]\n",
    "\n",
    "        return [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_idx, val_idx = train_test_split(\n",
    "    df.index, random_state=42, test_size=0.2, stratify = df.label.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_face_gen = DataGenerator(train_idx, df, embd_dict, embd_size=128)\n",
    "val_face_gen = DataGenerator(val_idx, df, embd_dict, embd_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in train_face_gen:\n",
    "    pass\n",
    "for x,y in val_face_gen:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Flatten,Input,Layer\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import merge, Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.utils import generic_utils\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def base():\n",
    "    xin = Input(shape=(128,))    \n",
    "    x1 = GaussianNoise(0.5)(xin)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    x1 = Dense(128)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = LeakyReLU(0.33)(x1)\n",
    "    x1 = Dropout(0.2)(x1)\n",
    "    \n",
    "    return Model(xin, x1)\n",
    "\n",
    "def face_detector():\n",
    "    base_model = base()\n",
    "    \n",
    "    x1 = Input(shape=(128,)) \n",
    "    x2 = Input(shape=(128,)) \n",
    "    embd1 = base_model(x1)\n",
    "    embd2 = base_model(x2)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([embd1, embd2])\n",
    "    \n",
    "    face_detector = Model(input = [x1, x2], output = distance)\n",
    "    return face_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_22 (Model)                (None, 128)          17024       input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           model_22[1][0]                   \n",
      "                                                                 model_22[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 17,024\n",
      "Trainable params: 16,768\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adishjain01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"la...)`\n"
     ]
    }
   ],
   "source": [
    "model = face_detector()\n",
    "adam = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=adam, metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 2s - loss: 42.5504 - accuracy: 0.5000 - val_loss: 2.7697 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      " - 1s - loss: 23.9082 - accuracy: 0.5000 - val_loss: 2.8095 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      " - 1s - loss: 12.1299 - accuracy: 0.5000 - val_loss: 1.6148 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      " - 1s - loss: 5.4742 - accuracy: 0.5000 - val_loss: 0.4362 - val_accuracy: 0.5050\n",
      "Epoch 5/50\n",
      " - 1s - loss: 2.4409 - accuracy: 0.5000 - val_loss: 0.0992 - val_accuracy: 0.6025\n",
      "Epoch 6/50\n",
      " - 1s - loss: 1.0957 - accuracy: 0.5000 - val_loss: 0.1183 - val_accuracy: 0.9750\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.3765 - accuracy: 0.5000 - val_loss: 0.2817 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.2341 - accuracy: 0.5544 - val_loss: 0.1941 - val_accuracy: 0.5075\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2107 - accuracy: 0.6744 - val_loss: 0.2298 - val_accuracy: 0.5725\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.1996 - accuracy: 0.7331 - val_loss: 0.2828 - val_accuracy: 0.6450\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.1953 - accuracy: 0.7394 - val_loss: 0.1645 - val_accuracy: 0.6750\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.1896 - accuracy: 0.7812 - val_loss: 0.2091 - val_accuracy: 0.7000\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.1888 - accuracy: 0.7812 - val_loss: 0.2189 - val_accuracy: 0.6950\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.1869 - accuracy: 0.7931 - val_loss: 0.1188 - val_accuracy: 0.7050\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.1846 - accuracy: 0.7900 - val_loss: 0.1675 - val_accuracy: 0.7550\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.1838 - accuracy: 0.7950 - val_loss: 0.1886 - val_accuracy: 0.7175\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.1789 - accuracy: 0.8087 - val_loss: 0.1080 - val_accuracy: 0.7775\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.1799 - accuracy: 0.8131 - val_loss: 0.2302 - val_accuracy: 0.7850\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.1784 - accuracy: 0.8125 - val_loss: 0.1685 - val_accuracy: 0.7600\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.1804 - accuracy: 0.8075 - val_loss: 0.1965 - val_accuracy: 0.8050\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.1784 - accuracy: 0.8094 - val_loss: 0.0815 - val_accuracy: 0.7725\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.1799 - accuracy: 0.8012 - val_loss: 0.1678 - val_accuracy: 0.7675\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.1747 - accuracy: 0.8250 - val_loss: 0.1568 - val_accuracy: 0.7725\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.1785 - accuracy: 0.8081 - val_loss: 0.1993 - val_accuracy: 0.7575\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.1741 - accuracy: 0.8281 - val_loss: 0.1582 - val_accuracy: 0.7550\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.1761 - accuracy: 0.8206 - val_loss: 0.3047 - val_accuracy: 0.7625\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "def lr_control(epoch):\n",
    "    if epoch < 20:\n",
    "        lr = 1e-3\n",
    "    elif epoch < 40:\n",
    "        lr = 3e-4\n",
    "    elif epoch >= 40:\n",
    "        lr = 2e-5\n",
    "    return lr\n",
    "\n",
    "callback = [ModelCheckpoint(f'best_model_saved_embd_conloss.h5', save_best_only=True),\n",
    "            EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20, restore_best_weights=True),\n",
    "            #ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=0.00000001, mode='max', verbose=1),\n",
    "           LearningRateScheduler(lr_control)]\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_face_gen,\n",
    "        validation_data=val_face_gen,\n",
    "        epochs=50,\n",
    "        verbose=2,\n",
    "    callbacks=callback\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
