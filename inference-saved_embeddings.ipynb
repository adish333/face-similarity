{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adishjain01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "facenet_base = load_model('facenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN\n",
    "import cv2\n",
    "from numpy import expand_dims\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face(filename, required_size=(160, 160)):\n",
    "    image = cv2.imread(filename)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = detector.detect_faces(image)\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    face = image[y1:y2, x1:x2]\n",
    "    face = cv2.resize(face, required_size)\n",
    "    return face.astype('float32')\n",
    "\n",
    "def get_embedding(model, face):\n",
    "    mean, std = face.mean(), face.std()\n",
    "    face = (face - mean) / std\n",
    "    samples = expand_dims(face, axis=0)\n",
    "    yhat = model.predict(samples)\n",
    "    return yhat[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_path = 'test1.jpg'\n",
    "image2_path = 'test2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face1 = get_face(image1_path)\n",
    "face1_embd = get_embedding(facenet_base, face1)\n",
    "\n",
    "face2 = get_face(image2_path)\n",
    "face2_embd = get_embedding(facenet_base, face2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\adishjain01\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_22 (Model)                (None, 128)          17024       input_36[0][0]                   \n",
      "                                                                 input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           model_22[1][0]                   \n",
      "                                                                 model_22[2][0]                   \n",
      "==================================================================================================\n",
      "Total params: 17,024\n",
      "Trainable params: 16,768\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "face_detector = load_model(\"best_model_saved_embd_conloss.h5\", custom_objects={'contrastive_loss':contrastive_loss})\n",
    "face_detector.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = face_detector.predict([[face1_embd], [face2_embd]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = 1 - distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are of same person\n"
     ]
    }
   ],
   "source": [
    "if similarity_score > 0.5:\n",
    "    print(\"The images are of same person\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
